---
title: 大模型参数说明
date: 2025-06-30
category: 大模型开发
tag: 大模型开发
timeline: true
article: true
---

模型参数是指模型在训练过程中所使用的参数，这些参数会影响模型的性能和效果。

## 模型参数

### 1. Max Tokens（最大生成长度）

* **作用**：限制模型生成文本的最大长度（以 token 为单位）。
* **Token 概念**：1 个 token ≈ 0.75 个英文单词 或 1 个中文汉字。
* **例子**：设置 `max_tokens = 100`，模型最多生成 100 个 token 的回复，之后就会自动停止。
* **影响**：
  - 数值越大，允许生成更长的回答
  - 数值越小，回答会被强制截断
  - 影响推理成本和响应时间
* **适用场景**：防止生成内容过长；控制响应长度。

---

### 2. Temperature（温度，控制随机性）

* **范围**：0 \~ 2（通常0.0-1.0），默认通常是 **0.7 或 1.0**
* **作用**：控制输出的**随机性与创造性**：
  * **低温度（0.0-0.3）**：生成更确定、一致的回答，适合事实性问题
  * **中温度（0.4-0.7）**：平衡创造性和准确性
  * **高温度（0.8-1.0+）**：生成更有创意、多样化的回答，但可能不够准确
* **类比**：像骰子投得更自由/不受限制。

---

### 3. Top-P（又称 nucleus sampling）

* **范围**：0 \~ 1，默认 **1.0**
* **作用**：控制从概率前 `p` 的词中采样，常和 temperature 搭配使用。
  * `Top-P = 1.0`：等价于使用所有词；
  * `Top-P = 0.9`：只从概率前 90% 的候选词中随机选择，排除尾部低概率词。
* **区别于 Top-K**：

  * Top-P 是“累积概率”的门槛；
  * Top-K 是“个数”的门槛。

---

### 4. Top-K（K值采样）

* **范围**：正整数，常见值：10、40、100
* **作用**：仅在前 `k` 个概率最高的词中采样（截断词汇表）。
  * `Top-K = 1`：始终选择概率最高的词（= 确定性回答）；
  * `Top-K = 10`：从前 10 个词中随机采样。
* **注意**：OpenAI 官方接口目前不支持 Top-K 设置，但某些模型（如 Cohere、LLama）支持。

---

### 5. Frequency Penalty（重复惩罚）

* **范围**：0 \~ 2，默认通常为 0
* **作用**：惩罚已经出现过的 token，**降低重复词的概率**。
* 效果：
  - **正值**：降低已出现词汇的重复概率
  - **负值**：增加词汇重复的可能性
  - **0**：不施加惩罚
* **例子**：防止模型不断重复「好的，好的，好的……」。

---

### 6. Thinking Budget（思考预算）

**定义**：为模型的"思考"过程分配的计算资源

- **概念**：类似于人类思考时间的计算等价物
- 作用：
  - 控制模型在生成回答前的推理深度
  - 影响复杂问题的解决质量
  - 平衡响应质量和计算成本
- 应用场景：
  - 复杂推理任务需要更多预算
  - 简单问答可以使用较少预算

---

### 推荐组合（参考值）

| 应用场景      | Temperature | Top-P | Frequency Penalty |
| ------------- | ----------- | ----- | ----------------- |
| 问答（准确）  | 0.2 – 0.4   | 0.9   | 0.0               |
| 文案写作/创意 | 0.8 – 1.2   | 0.95  | 0.2               |
| 技术文档生成  | 0.3 – 0.6   | 0.8   | 0.1               |
| 对话机器人    | 0.7 – 1.0   | 1.0   | 0.3               |
| 代码生成      | 0.0 – 0.2   | 0.8   | 0.0               |
| 避免重复回答  | 任意        | 任意  | ≥ 0.5             |

